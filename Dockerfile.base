# https://github.com/PINTO0309/openvino2tensorflow
FROM nvidia/cuda:11.6.2-cudnn8-devel-ubuntu20.04

ENV DEBIAN_FRONTEND=noninteractive
ARG OSVER=ubuntu2004
ARG TENSORFLOWVER=2.10.0
ARG CPVER=cp38
ARG OPENVINOGEN=2022
ARG OPENVINOVER=${OPENVINOGEN}.1.0
ARG TENSORRTVER=cuda11.6-trt8.4.0.6-ea-20220212
ARG ONNXRUNTIMEVER=1.12.1
ARG WKDIR=/home/user

# dash -> bash
RUN echo "dash dash/sh boolean false" | debconf-set-selections \
    && dpkg-reconfigure -p low dash
COPY bashrc ${WKDIR}/.bashrc
WORKDIR ${WKDIR}

COPY packages/* ${WKDIR}/

# Install dependencies (1)
RUN apt-get update \
    && apt-get install -y \
        automake autoconf libpng-dev nano python3-pip \
        curl zip unzip libtool swig zlib1g-dev pkg-config \
        python3-mock libpython3-dev libpython3-all-dev \
        g++ gcc make pciutils cpio gosu wget libmkldnn-dev \
        libgtk-3-dev libxtst-dev sudo apt-transport-https \
        build-essential gnupg git xz-utils vim libyaml-cpp-dev \
        libva-drm2 libva-x11-2 vainfo libva-wayland2 libva-glx2 \
        libva-dev libdrm-dev xorg xorg-dev protobuf-compiler \
        openbox libx11-dev libgl1-mesa-glx libgl1-mesa-dev \
        libtbb2 libtbb-dev libopenblas-dev libopenmpi-dev \
        python-is-python3 software-properties-common \
        libxcb-xinerama0 patchelf libusb-1.0-0-dev \
    && sed -i 's/# set linenumbers/set linenumbers/g' /etc/nanorc \
    && apt clean \
    && rm -rf /var/lib/apt/lists/*

# Install dependencies (2)
RUN pip3 install --upgrade pip \
    && pip install --upgrade numpy==1.23.2 \
    && pip install --upgrade tensorflowjs \
    && pip install --upgrade coremltools \
    && pip install --upgrade paddlepaddle \
    && pip install --upgrade lap \
    && pip install --upgrade pycocotools \
    && pip install --upgrade scipy \
    && pip install --upgrade paddle2onnx \
    && pip install --upgrade onnx \
    && pip install --upgrade onnxruntime-extensions \
    && pip install --upgrade onnxsim \
    && pip install --upgrade onnxmltools \
    && pip install --upgrade onnxconverter-common \
    && pip install --upgrade tf2onnx \
    && pip install --upgrade onnx-tf \
    && pip install --upgrade tensorflow-datasets \
    && pip install --upgrade openvino2tensorflow \
    && pip install --upgrade tflite2tensorflow \
    && pip install --upgrade gdown \
    && pip install --upgrade PyYAML \
    && pip install --upgrade matplotlib \
    && pip install --upgrade tf_slim \
    && pip install --upgrade pandas \
    && pip install --upgrade numexpr \
    && pip install --upgrade simple-onnx-processing-tools \
    && pip install --upgrade gluoncv \
    && pip install --upgrade dgl \
    && pip install --upgrade cmake \
    && pip install --upgrade ninja \
    && pip install --upgrade Cython \
    && pip install --upgrade setuptools \
    && pip install --upgrade wheel \
    && pip install --upgrade pafy \
    && pip install --upgrade youtube-dl \
    && pip install --upgrade blobconverter \
    && pip install pycuda==2022.1 \
    && pip uninstall -y onnxruntime onnxruntime-gpu \
    && pip install ${WKDIR}/onnxruntime_gpu-${ONNXRUNTIMEVER}-${CPVER}-none-linux_x86_64.whl \
    && rm ${WKDIR}/onnxruntime_gpu-${ONNXRUNTIMEVER}-${CPVER}-none-linux_x86_64.whl \
    && python -m pip install onnx_graphsurgeon \
        --index-url https://pypi.ngc.nvidia.com \
    && pip install \
        --force-reinstall \
        --extra-index-url https://download.pytorch.org/whl/cu116 \
            torch==1.12.1+cu116 \
            torchvision==0.13.1+cu116 \
            torchaudio==0.12.1+cu116 \
    && pip install scikit-image \
    && pip install performance-monitor \
    && pip install graphviz \
    && pip install pydot \
    && ldconfig \
    && pip cache purge \
    && apt clean \
    && rm -rf /var/lib/apt/lists/*

# Install custom tflite_runtime (MediaPipe Custom OP, FlexDelegate, XNNPACK enabled), flatc, edgetpu-compiler
# https://github.com/PINTO0309/TensorflowLite-bin
RUN chmod +x ${WKDIR}/tflite_runtime-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \
    && pip3 install --force-reinstall ${WKDIR}/tflite_runtime-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \
    && rm ${WKDIR}/tflite_runtime-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \
    && tar -zxvf ${WKDIR}/flatc.tar.gz \
    && chmod +x ${WKDIR}/flatc \
    && rm ${WKDIR}/flatc.tar.gz \
    && wget https://github.com/PINTO0309/tflite2tensorflow/raw/main/schema/schema.fbs \
    && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - \
    && echo "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main" | tee /etc/apt/sources.list.d/coral-edgetpu.list \
    && apt-get update \
    && apt-get install edgetpu-compiler \
    && pip cache purge \
    && apt clean \
    && rm -rf /var/lib/apt/lists/*

# Install TensorRT additional package
RUN dpkg -i ${WKDIR}/nv-tensorrt-repo-${OSVER}-${TENSORRTVER}_1-1_amd64.deb \
    && apt-key add /var/nv-tensorrt-repo-${OSVER}-${TENSORRTVER}/7fa2af80.pub \
    && apt-get update \
    && apt-get install -y --no-install-recommends \
        tensorrt=8.4.0.6-1+cuda11.6 \
        uff-converter-tf=8.4.0-1+cuda11.6 \
        graphsurgeon-tf=8.4.0-1+cuda11.6 \
        libnvinfer-dev=8.4.0-1+cuda11.6 \
        python3-libnvinfer=8.4.0-1+cuda11.6 \
        libnvinfer8=8.4.0-1+cuda11.6 \
        libnvinfer-plugin8=8.4.0-1+cuda11.6 \
        libnvparsers8=8.4.0-1+cuda11.6 \
        libnvinfer-bin=8.4.0-1+cuda11.6 \
        libnvinfer-plugin-dev=8.4.0-1+cuda11.6 \
        python3-libnvinfer-dev=8.4.0-1+cuda11.6 \
        libnvparsers-dev=8.4.0-1+cuda11.6 \
        libnvonnxparsers8=8.4.0-1+cuda11.6 \
        libnvonnxparsers-dev=8.4.0-1+cuda11.6 \
        libnvinfer-samples=8.4.0-1+cuda11.6 \
        libnvinfer-doc=8.4.0-1+cuda11.6 \
        onnx-graphsurgeon=8.4.0-1+cuda11.6 \
    && rm ${WKDIR}/nv-tensorrt-repo-${OSVER}-${TENSORRTVER}_1-1_amd64.deb \
    && cd /usr/src/tensorrt/samples/trtexec \
    && make \
    && apt clean \
    && rm -rf /var/lib/apt/lists/*

# # Install Custom TensorFlow (MediaPipe Custom OP, FlexDelegate, XNNPACK enabled)
# https://github.com/PINTO0309/Tensorflow-bin
RUN pip install --force-reinstall ${WKDIR}/tensorflow-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \
    && rm ${WKDIR}/tensorflow-${TENSORFLOWVER}-${CPVER}-none-linux_x86_64.whl \
    && pip cache purge \
    && apt clean \
    && rm -rf /var/lib/apt/lists/*

# Install onnx-tensorrt
# https://forums.developer.nvidia.com/t/subnormal-fp16-values-detected/220070
# https://github.com/NVIDIA/TensorRT/issues/2186
RUN git clone --recursive https://github.com/onnx/onnx-tensorrt \
    && cd onnx-tensorrt \
    # && git checkout bf5f48f2ffcdd4734f2a07c08571313180adeffd \
    && git checkout 9f82b2b6072be6c01f65306388e5c07621d3308f \
    && mkdir build \
    && cd build \
    && cmake .. -DTENSORRT_ROOT=/usr/src/tensorrt \
    && make -j$(nproc) \
    && make install

# Install torch2trt
RUN git clone https://github.com/NVIDIA-AI-IOT/torch2trt \
    && cd torch2trt \
    # && git checkout 540520700f969e13b921be1bb944c44d299ff406 \
    && git checkout 458394febf25b879cb6ea2e12f0060ef4beae7a3 \
    && python3 setup.py install

# Download the ultra-small sample data set for INT8 calibration
RUN mkdir sample_npy \
    && mv calibration_data_img_sample.npy sample_npy/

# LLVM
RUN wget https://apt.llvm.org/llvm.sh \
    && chmod +x llvm.sh \
    && ./llvm.sh 14 \
    && apt clean \
    && rm -rf /var/lib/apt/lists/*

# OpenVINO
RUN wget https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB \
    && apt-key add GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB \
    && echo "deb https://apt.repos.intel.com/openvino/${OPENVINOGEN} focal main" | \
        tee /etc/apt/sources.list.d/intel-openvino-${OPENVINOGEN}.list \
    && apt update \
    && apt install -y openvino-${OPENVINOVER} \
    && pip install openvino-dev==${OPENVINOVER} --no-deps \
    && pip install \
        defusedxml \
        addict \
        fast-ctc-decode \
        imagecodecs \
        jstyleson~=0.0.2 \
        lmdb \
        nibabel \
        nltk \
        openvino-telemetry \
        parasail \
        progress \
        py-cpuinfo \
        pyclipper \
        pydicom \
        rawpy \
        sentencepiece \
        shapely \
        texttable~=1.6.3 \
        tokenizers~=0.10.1 \
        transformers \
        requests>=2.25.1 \
    && /opt/intel/openvino_${OPENVINOGEN}/install_dependencies/install_openvino_dependencies.sh -y \
    && apt clean \
    && rm -rf /var/lib/apt/lists/*

# Clear caches
RUN apt clean \
    && rm -rf /var/lib/apt/lists/*

# Create a user who can sudo in the Docker container
ENV USERNAME=user
RUN echo "root:root" | chpasswd \
    && adduser --disabled-password --gecos "" "${USERNAME}" \
    && echo "${USERNAME}:${USERNAME}" | chpasswd \
    && echo "%${USERNAME}    ALL=(ALL)   NOPASSWD:    ALL" >> /etc/sudoers.d/${USERNAME} \
    && chmod 0440 /etc/sudoers.d/${USERNAME}
USER ${USERNAME}
RUN sudo chown ${USERNAME}:${USERNAME} ${WKDIR} \
    && sudo chmod 777 ${WKDIR}/.bashrc

# OpenCL settings - https://github.com/intel/compute-runtime/releases
RUN cd ${WKDIR} \
    && sudo dpkg -i libigdgmm12_22.1.2_amd64.deb \
    && sudo dpkg -i intel-igc-core_1.0.11061_amd64.deb \
    && sudo dpkg -i intel-igc-opencl_1.0.11061_amd64.deb \
    && sudo dpkg -i intel-level-zero-gpu_1.3.23034_amd64.deb \
    && sudo dpkg -i intel-level-zero-gpu-dbgsym_1.3.23034_amd64.deb \
    && sudo dpkg --auto-deconfigure --force-all -i intel-opencl-icd_22.17.23034_amd64.deb \
    && sudo dpkg -i intel-opencl-icd-dbgsym_22.17.23034_amd64.deb \
    && rm intel-igc-core_1.0.11061_amd64.deb \
    && rm intel-igc-opencl_1.0.11061_amd64.deb \
    && rm intel-level-zero-gpu_1.3.23034_amd64.deb \
    && rm intel-level-zero-gpu-dbgsym_1.3.23034_amd64.deb \
    && rm intel-opencl-icd_22.17.23034_amd64.deb \
    && rm intel-opencl-icd-dbgsym_22.17.23034_amd64.deb \
    && rm libigdgmm12_22.1.2_amd64.deb \
    && sudo apt clean \
    && sudo rm -rf /var/lib/apt/lists/*

# Final processing of onnx-tensorrt install
RUN echo 'GPU=$(python3 -c "import torch;print(torch.cuda.is_available())")' >> ${HOME}/.bashrc \
    && echo 'if [ $GPU = "True" ]; then' >> ${HOME}/.bashrc \
    && echo "export PATH=${PATH}:/usr/src/tensorrt/bin:/onnx-tensorrt/build" >> ${HOME}/.bashrc \
    && echo "cd ${HOME}/onnx-tensorrt" >> ${HOME}/.bashrc \
    && echo "sudo python setup.py install" >> ${HOME}/.bashrc \
    && echo "fi" >> ${HOME}/.bashrc \
    && echo "cd ${WKDIR}" >> ${HOME}/.bashrc \
    && echo "cd ${HOME}/workdir" >> ${HOME}/.bashrc \
    && echo "source /opt/intel/openvino_${OPENVINOGEN}/setupvars.sh" >> ${HOME}/.bashrc
